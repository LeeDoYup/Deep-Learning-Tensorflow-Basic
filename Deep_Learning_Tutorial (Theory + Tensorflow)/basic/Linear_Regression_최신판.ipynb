{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "## Linear Regression 모델로 1차원 x & y 변수 모델링 하기 \n",
    "\n",
    "### Step 1. 데이터 생성\n",
    "\n",
    "아래 예시는 y=0.1x + 0.3 직선을 따르는 데이터를 임의로 생성한 후,\n",
    "\n",
    "linear regression 모델을 통해 위의 데이터에 가장 적합한 파라미터를 Tensorflow로 찾는 예제 입니다.\n",
    "\n",
    "바로 아래 블록은 위의 직선식을 따르는 임의의 데이터를 생성한 코드입니다.\n",
    "주의할 점은 우리는 직선식을 \"전반적으로\" 따르는 임의의 데이터를 생성하는 것이기 때문에\n",
    "꼭, \"Random Noise\"를 추가해주어야합니다.\n",
    "\n",
    "(그렇지 않으면 생성한 데이터 역시, 직선을 바로 위에 그려지는 형태가 되버립니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_points = 1000\n",
    "vectors_set = []\n",
    "for i in range(num_points):\n",
    "    x1=np.random.normal(0.0, 0.55)\n",
    "    y1 = x1* 0.1 + 0.3 + np.random.normal(0.,0.03)\n",
    "    vectors_set.append([x1,y1])\n",
    "\n",
    "x_data = [v[0] for v in vectors_set]\n",
    "y_data = [v[1] for v in vectors_set]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_data, y_data, 'ro')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Tensorflow를 이용한 학습 모델 생성\n",
    "\n",
    "아래 코드는 tensorflow 라이브러리를 import하고,\n",
    "\n",
    "tf 내에서 제공하는 기능을 통하여 우리가 학습할 모델을 생성하는 단계입니다.\n",
    "\n",
    "우리가 다루는 X, Y 모두 1차원 데이터이므로 y= w * x + b 에서 기울기 w, 절편(또는 편향) b 모두\n",
    "\n",
    "스칼라(scalar) 값이 될 것입니다. Shape=[1], rank=0 이겠죠? \n",
    "\n",
    "중요한 사실은 rank=0 인 스칼라값에 대해서는 tf.matmul을 할 수 없으니 주의해야한다는 점입니다.\n",
    "\n",
    "이번 예제에서 학습의 대상은 w, b 입니다.\n",
    "\n",
    "Tensorflow에서 학습의 대상은 tf.Variable로 선언하며, 인자로 초기화 값을 선언하게 됩니다.\n",
    "\n",
    "우리의 목표는, W와 b 모두 tf.random_uniform을 통해 임의의 값으로 변수를 초기화 하는 것 입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W*x_data + b\n",
    "\n",
    "print W\n",
    "print b\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 생성하였으니, 이제 학습을 위한 준비를 해야합니다.\n",
    "앞에서 언급한 것처럼 (강의에서)\n",
    "\n",
    "학습을 위해서는 1) 초기화, 2) 학습의 기준인 loss function 생성, 3) 학습을 위한 optimizer 생성\n",
    "3가지 단계가 필요합니다.\n",
    "\n",
    "우선 학습의 기준인 loss function을 생성해봅시다.\n",
    "실수 값을 예측하는 경우, loss function은 주로 MSE(Mean Square Error)를 사용합니다.\n",
    "\n",
    "이번 예제에서 optimizer는 Gradient Descent Method를 사용해봅시다. 학습률은 0.5로 설정하겟습니다!\n",
    "\n",
    "우리의 목표는 생성한 optimizer를 통해 loss function을 최소화하는 파라미터 \"W, b\"를 찾는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print loss\n",
    "print optimizer, \"\\n\"\n",
    "\n",
    "print init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습\n",
    "\n",
    "이제 학습을 위한 준비가 모두 끝났습니다.\n",
    "학습을 시작해볼까요?\n",
    "\n",
    "처음 머신러닝을 접하실 때 많은 분이 헷갈려하는 사항이 있는데요.\n",
    "머신러닝에서의 학습은 한 번의 학습으로 최적의 파라미터를 찾는 것이 \"절대 아닙니다.\"\n",
    "\n",
    "다양한 최적화 방법이 있지만, 머신 러닝 세계에서는 기본적으로 \n",
    "\n",
    "반복적인 계산을 통해 \n",
    "\n",
    "점차적으로\n",
    "\n",
    "최적의 파라미터를 찾아갑니다.\n",
    "\n",
    "즉, 한 번 학습을 시키면 우리가 설정한 학습률과 loss function을 바탕으로 1회 업데이트가 되는 것이에요.\n",
    "\n",
    "loss function이 낮아지지 않을 때까지 학습하는 것이 일반적이지만, 이번 예제는 간단한 예이기 때문에\n",
    "\n",
    "10회 업데이트를 해보겠습니다.\n",
    "\n",
    "학습을 위해서는 train으로 설정한 오퍼레이션만 실행해주시면 됩니다.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train several steps\n",
    "\n",
    "for step in range(10):\n",
    "    sess.run(train)\n",
    "    print \"Step:\\t\", step\n",
    "    print \"W:\\t\", sess.run(W)\n",
    "    print \"b:\\t\", sess.run(b)\n",
    "    print \"Loss Value:\\t\", sess.run(loss)\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data, y_data, 'ro')\n",
    "plt.plot(x_data, sess.run(W)*x_data+sess.run(b))\n",
    "plt.xlabel('x')\n",
    "plt.xlim(-2,2)\n",
    "plt.ylabel('y')\n",
    "plt.ylim(0.1,0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
